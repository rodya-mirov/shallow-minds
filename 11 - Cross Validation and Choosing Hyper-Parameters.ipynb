{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cross Validation and Choosing Hyper-Parameters\n",
    "\n",
    "We've started along a bad path and it's time to address it and fix it.  We've got a lot of hyper-parameters that we choose, and if we just keep playing with them until we get test accuracy, we're actually using the test set for training purposes, which means our test accuracy isn't really \"fair\" anymore -- it's almost more like training set accuracy.\n",
    "\n",
    "If you do this, *performance on the test set does not necessarily indicate good performance on **new data**,* which is the actual point!\n",
    "\n",
    "On the other hand, we can't just guess the hyper-parameters.  They interact in funny ways that are hard to predict, and what was a good parameter on one dataset can be wildly offbase with another.  We have to choose them somehow!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Solution\n",
    "\n",
    "The solution is **cross-validation**.  It works like this:\n",
    "\n",
    "1. Split off some portion of the (original) training set and call it your \"validation set.\"  Call the remaining portion your (new) training set.  This should be done randomly to avoid bias.\n",
    "2. For each choice of hyper-parameters...\n",
    "    1. Train a network on the training set with those parameters.\n",
    "    2. Evaluate the performance of the network on the validation set.\n",
    "3. Pick the hyper-parameters that give the best results on the validation set\n",
    "4. Train a network on the whole training set (training+validation)\n",
    "5. Evaluate its performance on the test set, and this is your actual performance.\n",
    "\n",
    "So in a sense we're still just training the network on the training set, we're just doing cross-validation within the training set to choose our hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyper-Parameters So Far\n",
    "\n",
    "Just to review, here's the hyper-parameters (read, choices that the algorithm doesn't make for you) we already have:\n",
    "\n",
    "1. Depth of the network\n",
    "2. Number of neurons at each level\n",
    "3. Activation function at each level\n",
    "4. Cost function\n",
    "5. Initialization method\n",
    "6. Learning Rate\n",
    "7. Momentum\n",
    "8. L1 Penalties\n",
    "9. L2 Penalties\n",
    "10. Number of epochs\n",
    "11. Size of mini-batches\n",
    "\n",
    "And we're going to get a lot more.  To be fair, some of these have a \"right\" answer and we don't have to train them.  For example:\n",
    "\n",
    "1. We'll always use the appropriate Xavier initialization, rather than a uniform method.\n",
    "2. We'll always use the appropriate cost function; no need to compare CE and MSE for classification problems.\n",
    "3. We'll typically use as many epochs as we can stand with our hardware and time constraints.\n",
    "4. Batch size doesn't seem to matter very much, so we can just stick with a moderately sized number.\n",
    "\n",
    "We might even decide we always like hyperbolic tangent neurons (or rectifier neurons, whatever) and so on, but even if you have a favorite architecture that you just adore, you still need to pick lots of finicky little numbers, and what works on one dataset won't work on another.  Hence, cross validation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cross-Validation: Code\n",
    "\n",
    "Cross validation is super easy to implement.  There's actually already code in `sklearn` for this, but it's so easy to do by hand that it doesn't seem worth it. We scramble up the sets (like in the code for batching), then split them into two pieces.  This has a side effect of scrabling both sets, which doesn't really affect anything since we're scrambling anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def validation_split(X, Y, train_set_proportion):\n",
    "    scrambled_indices = np.random.permutation(len(X))\n",
    "    train_size = int(np.floor(len(X) * train_set_proportion))\n",
    "    \n",
    "    train_X = X[scrambled_indices[0:train_size]]\n",
    "    train_Y = Y[scrambled_indices[0:train_size]]\n",
    "    \n",
    "    valid_X = X[scrambled_indices[train_size:]]\n",
    "    valid_Y = Y[scrambled_indices[train_size:]]\n",
    "    \n",
    "    return train_X, train_Y, valid_X, valid_Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing Hyper-Parameters\n",
    "\n",
    "There are a lot of ways to choose hyper-parameters.  If the number of parameters is not too large, and the number of options is not too vast, you can just try every combination.  This is called **grid search**.  This is fine if you're just trying to choose (say) learning rate, momentum, and regularization (L1 and L2).  With three choices each, that means $3^4=81$ simulations, which is a lot, but not *that* many.  The word grid comes from imagining only two parameters, then drawing out an \"integer\" grid across the search space, and visiting each point on the grid.\n",
    "\n",
    "On the other hand, if you've got more parameters, or more options per parameter, it's simply not possible to search through all of them.  Worse, with so many options, there's a good chance that picking the best one among them would just be overfitting the validation set and get bad test error anyway.\n",
    "\n",
    "Bengio talks a lot about this topic (see <a href=\"http://arxiv.org/pdf/1206.5533v2.pdf\">his paper</a>, starting around page 16) and it's important enough that we will revisit it several times throughout these notes.  Choosing hyper-parameters is nearly as complicated, and just as important, as training the networks appropriately!\n",
    "\n",
    "But for now let's just implement a basic grid search and see where that gets us.\n",
    "\n",
    "One helpful note from that paper that we will use is that you should examine parameters uniformly on the \"log-domain;\" that is, don't look at 1, 2, 3, 4, but rather look at 1, 2, 4, 8.  This is because (for example) you're not going to see much change between 7 and 8, or at least not as much as you would between 1 and 2.  So it makes sense to fix a uniform ratio (a \"hyper-hyper-parameter\") and then spread out evenly along that.\n",
    "\n",
    "Also, it makes sense to look only at values of the parameters that could plausibly do well.  We know a learning rate of 38 is not appropriate; better to stick to plausible values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid Search: Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's write the code for the \"inner\" experiment; this is essentially the same as the old experiment code, except that it takes the training set as a parameter (instead of just using the global one) and doesn't have so many `print` statements, since that's going to get exhausting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from basic_nn import *\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "def optimize(act_fn, cost_fn, init_fn, learning_rate,\n",
    "             train_X, train_Y,\n",
    "             neuron_sizes, num_epochs, batch_size,\n",
    "             l1_cost=0, l2_cost=0,\n",
    "             momentum=0\n",
    "            ):\n",
    "    np.random.seed(313) # for determinism\n",
    "    \n",
    "    # Step 2: initialize\n",
    "    weights, biases = init_fn(n, k, neuron_sizes)\n",
    "    acts = [act_fn for _ in range(0, len(weights))]\n",
    "    acts[-1] = act_sigmoid # last one is always sigmoid\n",
    "    \n",
    "    # Step 3: train\n",
    "    t1 = time.time()\n",
    "    \n",
    "    weight_velocities = [0 for _ in range(0, len(weights))]\n",
    "    biases_velocities = [0 for _ in range(0, len(biases))]\n",
    "\n",
    "    for epoch in range(0, num_epochs):\n",
    "        # we'll keep track of the cost as we go\n",
    "        total_cost = 0\n",
    "        num_batches = 0\n",
    "\n",
    "        for X_mb, Y_mb in get_mini_batches(batch_size, train_X, train_Y):\n",
    "            x, z, y = forward_prop(weights, biases, acts, X_mb)\n",
    "\n",
    "            bp_grad_w, bp_grad_b = back_prop(weights, biases, acts, cost_fn, X_mb, Y_mb, x, y, z)\n",
    "            l1_grad_w = lasso_cost(l1_cost, weights, biases, diff=True)\n",
    "            l2_grad_w = ridge_cost(l2_cost, weights, biases, diff=True)\n",
    "\n",
    "            for i in range(0, len(weights)):\n",
    "                weight_grad = bp_grad_w[i] / len(X_mb)\n",
    "                weight_grad += l1_grad_w[i]\n",
    "                weight_grad += l2_grad_w[i]\n",
    "                \n",
    "                weight_velocities[i] = weight_velocities[i] * momentum + weight_grad\n",
    "                weights[i] -= weight_velocities[i] * learning_rate\n",
    "                \n",
    "                biases_grad = bp_grad_b[i] / len(X_mb)\n",
    "                \n",
    "                biases_velocities[i] = biases_velocities[i] * momentum + biases_grad\n",
    "                biases[i] -= biases_velocities[i] * learning_rate\n",
    "\n",
    "            total_cost += cost_fn(y[-1], Y_mb, aggregate=True)\n",
    "            num_batches += 1\n",
    "\n",
    "        cost = total_cost / num_batches # average cost\n",
    "    \n",
    "    return weights, biases, acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the \"outer experiment.\"  For now we'll just talk about optimizing learning rate, L1 and L2 costs, and momentum, assuming the other values can be picked by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import itertools as it\n",
    "\n",
    "def run_exp(act_fn, cost_fn, init_fn, learning_rate_range,\n",
    "            train_X, train_Y,\n",
    "            neuron_sizes, num_epochs, batch_size,\n",
    "            l1_cost_range, l2_cost_range,\n",
    "            momentum_range\n",
    "           ):\n",
    "    \n",
    "    t1 = time.time()\n",
    "    \n",
    "    # Combine all the search into one loop...\n",
    "    options = it.product(learning_rate_range, l1_cost_range, l2_cost_range, momentum_range)\n",
    "    \n",
    "    # Split the data into train/validation\n",
    "    train_X, train_Y, valid_X, valid_Y = validation_split(train_X, train_Y, 0.7)\n",
    "    best_validation_success = -1\n",
    "    \n",
    "    # Loop through all options ...\n",
    "    sims_accomplished = 0\n",
    "    for option in options:\n",
    "        learning_rate_unscaled = option[0]\n",
    "        l1_cost_unscaled = option[1]\n",
    "        l2_cost_unscaled = option[2]\n",
    "        momentum_unscaled = option[3]\n",
    "        \n",
    "        # Standard fixes\n",
    "        learning_rate = learning_rate_unscaled * (1-momentum_unscaled)\n",
    "        l1_cost = l1_cost_unscaled / len(train_X)\n",
    "        l2_cost = l2_cost_unscaled / len(train_X)\n",
    "        momentum = momentum_unscaled\n",
    "        \n",
    "        # Train them up\n",
    "        weights, biases, acts = optimize(act_fn, cost_fn, init_fn,\n",
    "                                         learning_rate, train_X, train_Y,\n",
    "                                         neuron_sizes, num_epochs, batch_size,\n",
    "                                         l1_cost=l1_cost, l2_cost=l2_cost,\n",
    "                                         momentum=momentum)\n",
    "        \n",
    "        # Evaluate the results\n",
    "        _, _, train_Y_hat = forward_prop(weights, biases, acts, train_X)\n",
    "        train_success = classification_success_rate(train_Y_hat[-1], train_Y)\n",
    "        \n",
    "        _, _, valid_Y_hat = forward_prop(weights, biases, acts, valid_X)\n",
    "        valid_success = classification_success_rate(valid_Y_hat[-1], valid_Y)\n",
    "        \n",
    "        args = (100*valid_success, 100*train_success, learning_rate_unscaled, l1_cost_unscaled, l2_cost_unscaled, momentum)\n",
    "        \n",
    "        # Output for each simulation ...\n",
    "        print(\"Got {0:0.3f}% validation, {1:0.3f}% train with LR={2:0.3f}, L1={3:0.3f}, L2={4:0.3f}, Mm={5:0.3f}\".format(*args))\n",
    "        \n",
    "        # Keep track of the best results\n",
    "        if valid_success > best_validation_success:\n",
    "            best_validation_success = valid_success\n",
    "            best_weights, best_biases, best_acts = weights, biases, acts\n",
    "            print(\"New record!\")\n",
    "        \n",
    "        sims_accomplished += 1\n",
    "        print(\"Finished {0} simulations after {1:0.3f} seconds.\".format(sims_accomplished, time.time()-t1))\n",
    "        print()\n",
    "    \n",
    "    return best_weights, best_biases, best_acts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiments\n",
    "\n",
    "We'll still use the MNIST dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from mnist_import import get_mnist_nice\n",
    "\n",
    "train_X, train_Y, test_X, test_Y = get_mnist_nice()\n",
    "\n",
    "n = train_X.shape[1]\n",
    "k = train_Y.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 81 experiments to run.\n",
      "Got 97.389% validation, 99.307% train with LR=0.500, L1=0.250, L2=0.250, Mm=0.800\n",
      "New record!\n",
      "Finished 1 simulations after 120.553 seconds.\n",
      "\n",
      "Got 97.450% validation, 99.374% train with LR=0.500, L1=0.250, L2=0.250, Mm=0.900\n",
      "New record!\n",
      "Finished 2 simulations after 237.014 seconds.\n",
      "\n",
      "Got 97.239% validation, 99.236% train with LR=0.500, L1=0.250, L2=0.250, Mm=0.950\n",
      "Finished 3 simulations after 345.457 seconds.\n",
      "\n",
      "Got 97.539% validation, 99.310% train with LR=0.500, L1=0.250, L2=0.500, Mm=0.800\n",
      "New record!\n",
      "Finished 4 simulations after 453.345 seconds.\n",
      "\n",
      "Got 97.333% validation, 99.298% train with LR=0.500, L1=0.250, L2=0.500, Mm=0.900\n",
      "Finished 5 simulations after 563.659 seconds.\n",
      "\n",
      "Got 97.078% validation, 99.036% train with LR=0.500, L1=0.250, L2=0.500, Mm=0.950\n",
      "Finished 6 simulations after 685.234 seconds.\n",
      "\n",
      "Got 97.356% validation, 99.164% train with LR=0.500, L1=0.250, L2=1.000, Mm=0.800\n",
      "Finished 7 simulations after 795.295 seconds.\n",
      "\n",
      "Got 97.489% validation, 99.279% train with LR=0.500, L1=0.250, L2=1.000, Mm=0.900\n",
      "Finished 8 simulations after 902.292 seconds.\n",
      "\n",
      "Got 97.061% validation, 98.795% train with LR=0.500, L1=0.250, L2=1.000, Mm=0.950\n",
      "Finished 9 simulations after 1009.558 seconds.\n",
      "\n",
      "Got 97.089% validation, 98.871% train with LR=0.500, L1=0.500, L2=0.250, Mm=0.800\n",
      "Finished 10 simulations after 1118.266 seconds.\n",
      "\n",
      "Got 97.422% validation, 99.069% train with LR=0.500, L1=0.500, L2=0.250, Mm=0.900\n",
      "Finished 11 simulations after 1225.414 seconds.\n",
      "\n",
      "Got 96.683% validation, 98.464% train with LR=0.500, L1=0.500, L2=0.250, Mm=0.950\n",
      "Finished 12 simulations after 1332.103 seconds.\n",
      "\n",
      "Got 97.367% validation, 98.995% train with LR=0.500, L1=0.500, L2=0.500, Mm=0.800\n",
      "Finished 13 simulations after 1440.652 seconds.\n",
      "\n",
      "Got 97.411% validation, 98.998% train with LR=0.500, L1=0.500, L2=0.500, Mm=0.900\n",
      "Finished 14 simulations after 1547.822 seconds.\n",
      "\n",
      "Got 96.833% validation, 98.524% train with LR=0.500, L1=0.500, L2=0.500, Mm=0.950\n",
      "Finished 15 simulations after 1655.392 seconds.\n",
      "\n",
      "Got 97.256% validation, 98.881% train with LR=0.500, L1=0.500, L2=1.000, Mm=0.800\n",
      "Finished 16 simulations after 1762.846 seconds.\n",
      "\n",
      "Got 97.322% validation, 98.967% train with LR=0.500, L1=0.500, L2=1.000, Mm=0.900\n",
      "Finished 17 simulations after 1876.685 seconds.\n",
      "\n",
      "Got 96.744% validation, 98.438% train with LR=0.500, L1=0.500, L2=1.000, Mm=0.950\n",
      "Finished 18 simulations after 1987.432 seconds.\n",
      "\n",
      "Got 97.033% validation, 98.486% train with LR=0.500, L1=1.000, L2=0.250, Mm=0.800\n",
      "Finished 19 simulations after 2095.247 seconds.\n",
      "\n",
      "Got 97.217% validation, 98.579% train with LR=0.500, L1=1.000, L2=0.250, Mm=0.900\n",
      "Finished 20 simulations after 2196.857 seconds.\n",
      "\n",
      "Got 96.556% validation, 97.983% train with LR=0.500, L1=1.000, L2=0.250, Mm=0.950\n",
      "Finished 21 simulations after 2298.568 seconds.\n",
      "\n",
      "Got 96.983% validation, 98.426% train with LR=0.500, L1=1.000, L2=0.500, Mm=0.800\n",
      "Finished 22 simulations after 2402.068 seconds.\n",
      "\n",
      "Got 97.133% validation, 98.521% train with LR=0.500, L1=1.000, L2=0.500, Mm=0.900\n",
      "Finished 23 simulations after 2503.993 seconds.\n",
      "\n",
      "Got 96.556% validation, 97.971% train with LR=0.500, L1=1.000, L2=0.500, Mm=0.950\n",
      "Finished 24 simulations after 2605.164 seconds.\n",
      "\n",
      "Got 96.983% validation, 98.336% train with LR=0.500, L1=1.000, L2=1.000, Mm=0.800\n",
      "Finished 25 simulations after 2707.170 seconds.\n",
      "\n",
      "Got 97.039% validation, 98.431% train with LR=0.500, L1=1.000, L2=1.000, Mm=0.900\n",
      "Finished 26 simulations after 2808.432 seconds.\n",
      "\n",
      "Got 96.567% validation, 97.998% train with LR=0.500, L1=1.000, L2=1.000, Mm=0.950\n",
      "Finished 27 simulations after 2910.673 seconds.\n",
      "\n",
      "Got 97.406% validation, 99.340% train with LR=1.000, L1=0.250, L2=0.250, Mm=0.800\n",
      "Finished 28 simulations after 3016.668 seconds.\n",
      "\n",
      "Got 97.339% validation, 99.236% train with LR=1.000, L1=0.250, L2=0.250, Mm=0.900\n",
      "Finished 29 simulations after 3120.160 seconds.\n",
      "\n",
      "Got 97.344% validation, 99.298% train with LR=1.000, L1=0.250, L2=0.250, Mm=0.950\n",
      "Finished 30 simulations after 3225.996 seconds.\n",
      "\n",
      "Got 97.400% validation, 99.331% train with LR=1.000, L1=0.250, L2=0.500, Mm=0.800\n",
      "Finished 31 simulations after 3328.868 seconds.\n",
      "\n",
      "Got 97.311% validation, 99.164% train with LR=1.000, L1=0.250, L2=0.500, Mm=0.900\n",
      "Finished 32 simulations after 3431.183 seconds.\n",
      "\n",
      "Got 97.367% validation, 99.145% train with LR=1.000, L1=0.250, L2=0.500, Mm=0.950\n",
      "Finished 33 simulations after 3533.287 seconds.\n",
      "\n",
      "Got 97.483% validation, 99.152% train with LR=1.000, L1=0.250, L2=1.000, Mm=0.800\n",
      "Finished 34 simulations after 3635.113 seconds.\n",
      "\n",
      "Got 97.261% validation, 99.048% train with LR=1.000, L1=0.250, L2=1.000, Mm=0.900\n",
      "Finished 35 simulations after 3737.833 seconds.\n",
      "\n",
      "Got 97.244% validation, 99.057% train with LR=1.000, L1=0.250, L2=1.000, Mm=0.950\n",
      "Finished 36 simulations after 3839.490 seconds.\n",
      "\n",
      "Got 97.294% validation, 99.060% train with LR=1.000, L1=0.500, L2=0.250, Mm=0.800\n",
      "Finished 37 simulations after 3941.577 seconds.\n",
      "\n",
      "Got 97.089% validation, 98.886% train with LR=1.000, L1=0.500, L2=0.250, Mm=0.900\n",
      "Finished 38 simulations after 4043.782 seconds.\n",
      "\n",
      "Got 96.644% validation, 98.390% train with LR=1.000, L1=0.500, L2=0.250, Mm=0.950\n",
      "Finished 39 simulations after 4145.474 seconds.\n",
      "\n",
      "Got 97.067% validation, 98.790% train with LR=1.000, L1=0.500, L2=0.500, Mm=0.800\n",
      "Finished 40 simulations after 4247.076 seconds.\n",
      "\n",
      "Got 97.133% validation, 98.700% train with LR=1.000, L1=0.500, L2=0.500, Mm=0.900\n",
      "Finished 41 simulations after 4349.749 seconds.\n",
      "\n",
      "Got 97.250% validation, 98.698% train with LR=1.000, L1=0.500, L2=0.500, Mm=0.950\n",
      "Finished 42 simulations after 4454.384 seconds.\n",
      "\n",
      "Got 97.294% validation, 98.795% train with LR=1.000, L1=0.500, L2=1.000, Mm=0.800\n",
      "Finished 43 simulations after 4556.109 seconds.\n",
      "\n",
      "Got 97.150% validation, 98.721% train with LR=1.000, L1=0.500, L2=1.000, Mm=0.900\n",
      "Finished 44 simulations after 4658.033 seconds.\n",
      "\n",
      "Got 96.778% validation, 98.390% train with LR=1.000, L1=0.500, L2=1.000, Mm=0.950\n",
      "Finished 45 simulations after 4760.296 seconds.\n",
      "\n",
      "Got 96.722% validation, 98.236% train with LR=1.000, L1=1.000, L2=0.250, Mm=0.800\n",
      "Finished 46 simulations after 4861.361 seconds.\n",
      "\n",
      "Got 96.878% validation, 98.207% train with LR=1.000, L1=1.000, L2=0.250, Mm=0.900\n",
      "Finished 47 simulations after 4963.444 seconds.\n",
      "\n",
      "Got 96.839% validation, 98.233% train with LR=1.000, L1=1.000, L2=0.250, Mm=0.950\n",
      "Finished 48 simulations after 5064.379 seconds.\n",
      "\n",
      "Got 96.372% validation, 97.788% train with LR=1.000, L1=1.000, L2=0.500, Mm=0.800\n",
      "Finished 49 simulations after 5165.643 seconds.\n",
      "\n",
      "Got 96.872% validation, 98.279% train with LR=1.000, L1=1.000, L2=0.500, Mm=0.900\n",
      "Finished 50 simulations after 5266.602 seconds.\n",
      "\n",
      "Got 96.617% validation, 97.921% train with LR=1.000, L1=1.000, L2=0.500, Mm=0.950\n",
      "Finished 51 simulations after 5367.583 seconds.\n",
      "\n",
      "Got 96.817% validation, 98.229% train with LR=1.000, L1=1.000, L2=1.000, Mm=0.800\n",
      "Finished 52 simulations after 5468.138 seconds.\n",
      "\n",
      "Got 96.833% validation, 98.095% train with LR=1.000, L1=1.000, L2=1.000, Mm=0.900\n",
      "Finished 53 simulations after 5569.570 seconds.\n",
      "\n",
      "Got 96.756% validation, 98.002% train with LR=1.000, L1=1.000, L2=1.000, Mm=0.950\n",
      "Finished 54 simulations after 5670.122 seconds.\n",
      "\n",
      "Got 97.144% validation, 98.933% train with LR=2.000, L1=0.250, L2=0.250, Mm=0.800\n",
      "Finished 55 simulations after 5773.597 seconds.\n",
      "\n",
      "Got 97.189% validation, 98.931% train with LR=2.000, L1=0.250, L2=0.250, Mm=0.900\n",
      "Finished 56 simulations after 5876.579 seconds.\n",
      "\n",
      "Got 97.122% validation, 98.824% train with LR=2.000, L1=0.250, L2=0.250, Mm=0.950\n",
      "Finished 57 simulations after 5979.279 seconds.\n",
      "\n",
      "Got 97.072% validation, 98.719% train with LR=2.000, L1=0.250, L2=0.500, Mm=0.800\n",
      "Finished 58 simulations after 6081.418 seconds.\n",
      "\n",
      "Got 96.828% validation, 98.581% train with LR=2.000, L1=0.250, L2=0.500, Mm=0.900\n",
      "Finished 59 simulations after 6184.378 seconds.\n",
      "\n",
      "Got 96.972% validation, 98.605% train with LR=2.000, L1=0.250, L2=0.500, Mm=0.950\n",
      "Finished 60 simulations after 6286.282 seconds.\n",
      "\n",
      "Got 96.894% validation, 98.474% train with LR=2.000, L1=0.250, L2=1.000, Mm=0.800\n",
      "Finished 61 simulations after 6388.789 seconds.\n",
      "\n",
      "Got 97.167% validation, 98.645% train with LR=2.000, L1=0.250, L2=1.000, Mm=0.900\n",
      "Finished 62 simulations after 6491.716 seconds.\n",
      "\n",
      "Got 96.883% validation, 98.438% train with LR=2.000, L1=0.250, L2=1.000, Mm=0.950\n",
      "Finished 63 simulations after 6593.938 seconds.\n",
      "\n",
      "Got 97.011% validation, 98.619% train with LR=2.000, L1=0.500, L2=0.250, Mm=0.800\n",
      "Finished 64 simulations after 6695.765 seconds.\n",
      "\n",
      "Got 96.317% validation, 97.643% train with LR=2.000, L1=0.500, L2=0.250, Mm=0.900\n",
      "Finished 65 simulations after 6799.440 seconds.\n",
      "\n",
      "Got 97.156% validation, 98.621% train with LR=2.000, L1=0.500, L2=0.250, Mm=0.950\n",
      "Finished 66 simulations after 6901.246 seconds.\n",
      "\n",
      "Got 96.778% validation, 98.343% train with LR=2.000, L1=0.500, L2=0.500, Mm=0.800\n",
      "Finished 67 simulations after 7003.640 seconds.\n",
      "\n",
      "Got 97.078% validation, 98.407% train with LR=2.000, L1=0.500, L2=0.500, Mm=0.900\n",
      "Finished 68 simulations after 7105.560 seconds.\n",
      "\n",
      "Got 96.244% validation, 97.743% train with LR=2.000, L1=0.500, L2=0.500, Mm=0.950\n",
      "Finished 69 simulations after 7208.000 seconds.\n",
      "\n",
      "Got 96.556% validation, 98.069% train with LR=2.000, L1=0.500, L2=1.000, Mm=0.800\n",
      "Finished 70 simulations after 7309.564 seconds.\n",
      "\n",
      "Got 96.928% validation, 98.060% train with LR=2.000, L1=0.500, L2=1.000, Mm=0.900\n",
      "Finished 71 simulations after 7411.599 seconds.\n",
      "\n",
      "Got 95.722% validation, 97.126% train with LR=2.000, L1=0.500, L2=1.000, Mm=0.950\n",
      "Finished 72 simulations after 7513.280 seconds.\n",
      "\n",
      "Got 96.700% validation, 97.881% train with LR=2.000, L1=1.000, L2=0.250, Mm=0.800\n",
      "Finished 73 simulations after 7614.748 seconds.\n",
      "\n",
      "Got 96.483% validation, 97.710% train with LR=2.000, L1=1.000, L2=0.250, Mm=0.900\n",
      "Finished 74 simulations after 7715.963 seconds.\n",
      "\n",
      "Got 96.472% validation, 97.738% train with LR=2.000, L1=1.000, L2=0.250, Mm=0.950\n",
      "Finished 75 simulations after 7819.610 seconds.\n",
      "\n",
      "Got 96.522% validation, 97.731% train with LR=2.000, L1=1.000, L2=0.500, Mm=0.800\n",
      "Finished 76 simulations after 7920.711 seconds.\n",
      "\n",
      "Got 95.372% validation, 96.476% train with LR=2.000, L1=1.000, L2=0.500, Mm=0.900\n",
      "Finished 77 simulations after 8022.478 seconds.\n",
      "\n",
      "Got 95.589% validation, 96.390% train with LR=2.000, L1=1.000, L2=0.500, Mm=0.950\n",
      "Finished 78 simulations after 8123.817 seconds.\n",
      "\n",
      "Got 96.194% validation, 97.381% train with LR=2.000, L1=1.000, L2=1.000, Mm=0.800\n",
      "Finished 79 simulations after 8225.431 seconds.\n",
      "\n",
      "Got 96.744% validation, 97.788% train with LR=2.000, L1=1.000, L2=1.000, Mm=0.900\n",
      "Finished 80 simulations after 8326.917 seconds.\n",
      "\n",
      "Got 96.228% validation, 97.398% train with LR=2.000, L1=1.000, L2=1.000, Mm=0.950\n",
      "Finished 81 simulations after 8428.248 seconds.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "act_fn = act_tanh\n",
    "cost_fn = cost_CE\n",
    "init_fn = initialize_xavier_tanh\n",
    "\n",
    "learning_rate_range = [0.5, 1, 2]\n",
    "\n",
    "neuron_sizes = [100, 60, 40]\n",
    "num_epochs = 20\n",
    "batch_size = 50\n",
    "\n",
    "l1_cost_range = [0.25, 0.5, 1]\n",
    "l2_cost_range = [0.25, 0.5, 1]\n",
    "\n",
    "momentum_range = [0.8, 0.9, 0.95]\n",
    "\n",
    "print(\"There are {0} experiments to run.\".format(3*3*3*3))\n",
    "weights, biases, acts = run_exp(act_fn, cost_fn, init_fn, learning_rate_range,\n",
    "                                train_X, train_Y,\n",
    "                                neuron_sizes, num_epochs, batch_size,\n",
    "                                l1_cost_range, l2_cost_range,\n",
    "                                momentum_range\n",
    "                               )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, that took an incredibly long time (in comparison to the other experiments).  But the ideal parameters (from the options given) were a learning rate of `0.5`, L1 cost of `0.25`, L2 cost of `0.5`, and momentum of `0.8`.  Let's try those parameters with more epochs and see how it gets us on the test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 99.620% success rate on the training data.\n",
      "Got 98.000% success rate on the test data.\n"
     ]
    }
   ],
   "source": [
    "act_fn = act_tanh\n",
    "cost_fn = cost_CE\n",
    "init_fn = initialize_xavier_tanh\n",
    "\n",
    "learning_rate = 0.5\n",
    "\n",
    "neuron_sizes = [100, 60, 40]\n",
    "num_epochs = 40\n",
    "batch_size = 50\n",
    "\n",
    "l1_cost = 0.25\n",
    "l2_cost = 0.5\n",
    "\n",
    "momentum = 0.8\n",
    "\n",
    "# Fix up the parameters, as this agrees with what happened in the experiment\n",
    "l1_cost /= len(train_X)\n",
    "l2_cost /= len(train_X)\n",
    "learning_rate *= 1 - momentum\n",
    "\n",
    "# train it up; note this is the whole dataset now\n",
    "weights, biases, acts = optimize(act_fn, cost_fn, init_fn, learning_rate,\n",
    "                                 train_X, train_Y,\n",
    "                                 neuron_sizes, num_epochs, batch_size,\n",
    "                                 l1_cost=l1_cost, l2_cost=l2_cost,\n",
    "                                 momentum=momentum\n",
    "                                )\n",
    "\n",
    "_, _, y = forward_prop(weights, biases, acts, train_X)\n",
    "train_Y_hat = y[-1]\n",
    "\n",
    "train_success = classification_success_rate(train_Y_hat, train_Y)\n",
    "print(\"Got {0:0.3f}% success rate on the training data.\".format(100 * train_success))\n",
    "\n",
    "_, _, y = forward_prop(weights, biases, acts, test_X)\n",
    "test_Y_hat = y[-1]\n",
    "\n",
    "test_success = classification_success_rate(test_Y_hat, test_Y)\n",
    "print(\"Got {0:0.3f}% success rate on the test data.\".format(100 * test_success))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Excellent!  Our first 98% success rate on the test data. It makes you wonder if this was really the ideal set of parameters, though.  Maybe more regularization or more momentum (or both) would have done better on the validation phase if they had been given more epochs, but there just wasn't the computing time to do so.\n",
    "\n",
    "Also, we could have experimented with different network architectures (depth, number of neurons, activation functions) and gotten even a better search, but again, time limitations bit us. In a later notebook, we may talk about how to use AWS (or similar services) to parallelize this search and get this done in a tiny fraction of the time.  However, for right now, we stop here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Wrapup and Summary\n",
    "\n",
    "We introduced **cross validation** as a way to avoid training on the test data.  We also introduced the **grid search** as a primitive way of exploring possible settings of the hyperparameters.  We did a large scale experiment which took hours to run, but found a decent set of parameters that did well on the test set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework\n",
    "\n",
    "Try this yourself!  Find other ranges to search, or consider different variables to optimize on.  If your computer runs better than mine, try a longer simulation and see how it goes.  We'll talk about more advanced parameter searches later on, too."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
